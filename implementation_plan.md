# AI Backend Implementation Plan

## Objective
Implement a robust, verification-driven AI backend for the Resume Editor. The system must ensure that any LaTeX code generated by the AI is syntactically correct and compiles successfully before being presented to the user.

## Architecture

### 1. API Route: `/api/chat`
This will be the main entry point for the frontend chat interface.

**Payload:**
```json
{
  "projectId": "...",
  "messages": [...],
  "context": [
    { "id": "experience", "content": "..." }
  ]
}
```

### 2. The "Checker" Workflow (Robustness Layer)

We will implement a **Sandbox Compilation Strategy** to verify AI output.

1.  **Structured AI Output**:
    *   We will instruct the AI to return data in a strict **JSON format**.
    *   This avoids parsing ambiguity and handles multiple section updates simultaneously.
    *   Format:
        ```json
        {
          "modifications": [
            { "section_id": "experience", "new_content": "..." }
          ],
          "explanation": "I have updated the bullet points..."
        }
        ```

2.  **Sandbox Environment**:
    *   For every request that involves code changes, we create a **temporary directory** on the server.
    *   **Fetch**: We download the current state of the project files (main.tex, cls files, images) from Supabase Storage into this temp dir.
    *   **Apply**: We inject the AI's suggested `new_content` into the `main.tex` file (replacing the old section content).

3.  **Compilation Verification**:
    *   We execute `pdflatex -interaction=nonstopmode main.tex` in the temp directory.
    *   **Check**: We inspect the exit code and the `.log` file.
    *   **Pass**: If exit code is 0 (or PDF is generated), the code is verified.
    *   **Fail**: If compilation fails, we capture the error.

4.  **Self-Correction Loop (Advanced)**:
    *   If compilation fails, we can feed the LaTeX error log *back* to the AI: "The code you generated caused this error: [Error Log]. Please fix it."
    *   The AI generates a new attempt.
    *   We re-run the verification.
    *   (Limit to 1-2 retries to prevent infinite loops).

### 3. Response to Frontend
*   **Success**: Return the validated `modifications` and the AI's `explanation`. The frontend updates the UI and shows a "Verified" indicator.
*   **Failure**: If all retries fail, inform the user that the AI couldn't generate valid code and show the error.

## Implementation Steps

1.  **Setup Backend**: Create `/src/app/api/chat/route.ts`.
2.  **LLM Integration**: Integrate with an LLM provider (e.g., Google Gemini or OpenAI) using the Vercel AI SDK or direct API.
3.  **LaTeX Compiler Utility**: Create a helper `src/lib/latex-compiler.ts` that wraps the local `pdflatex` command.
4.  **Orchestrator**: Implement the logic to download files, apply patches, compile, and retry.

## Prerequisites
*   **MiKTeX/TeXLive**: You have confirmed `pdflatex` is installed locally. This is perfect for the dev environment.
